apiVersion: apps/v1
kind: Deployment
metadata:
  name: second-app-deployment
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: second-app
        tier: backend
    spec:
      containers:
      - name: second-app-container
        image: cbagade/mon-setup:v1
        imagePullPolicy: Always
        ports:
          - containerPort: 5000        
        # k8 uses liveness probes to know when to restart a container.
        # For example, liveness probes could catch a deadlock, where an application is running,
        # but unable to make progress.
        # Restarting a container in such a state can help to make the application more available despite bugs
        livenessProbe:
          # will try to make a get request at path /greetings on port 5000 in a interval of 10 seconds
          # after 5 seconds, while container become stable (up/running)
          httpGet:
            path: /greetings
            port: 5000
          periodSeconds: 10
          initialDelaySeconds: 5
  selector:
    matchLabels:
      app: second-app
      tier: backend


# kubectl apply -f liveness_deployment.yaml -f service.yaml

# kubectl get pods -w
# wait till it comes to running status
# curl http://localhost:30008/greetings
# pod will respond to above API
# on other terminal hit following API multiple times
# curl http://localhost:30008/error
# this will make pod go in error state but k8 will bring it back and can be seen from restart count of pod
# wait for sometime to let pod become stable
# curl http://localhost:30008/greetings
# pod will respond to above error

# on other terminal
# hit following API 3-4 times so that , both pods goes in deadlock mode
# curl http://localhost:30008/lock
# now try
# curl http://localhost:30008/greetings
# there won't be any response, since same lock is used in greetings method (observe app.py)
# but observe
# kubectl get pods -w
# the liveness probe will also try /greetings and when it is not getting response it will restart pod
# after restart try on other terminale
# curl http://localhost:30008/greetings
# this time you will get response

# also describe the pod to see reasons for restarting
# kubectl describe pod <pod_name>

# clean up
# kubectl delete -f liveness_deployment.yaml -f service.yaml
